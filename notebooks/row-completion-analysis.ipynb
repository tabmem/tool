{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis and Plots of row completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# append the parent directory to the path\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import jellyfish\n",
    "\n",
    "import yaml\n",
    "\n",
    "import experiment_utils\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "import analysis \n",
    "import utils\n",
    "\n",
    "from row_independence import statistical_feature_prediction_test\n",
    "\n",
    "# re-load upon module change\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### row completion test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in ['IRIS', 'uci-wine', 'titanic-train', 'sklearn-diabetes', 'openml-diabetes', 'california-housing', 'adult', 'spaceship-titanic-train']:\n",
    "    for model in ['gpt-3.5-turbo', 'gpt-4-32k-0314']:\n",
    "        completion_df = pd.read_csv(f'../results/{model}/row-completion/{dataset}.csv', dtype=str)\n",
    "        \n",
    "        test_prefixes = completion_df['prefix'].tolist()\n",
    "        test_suffixes = completion_df['suffix'].tolist()\n",
    "        responses = completion_df['response'].tolist()\n",
    "\n",
    "        try:\n",
    "            num_exact_matches = 0\n",
    "            for test_suffix, response in zip(test_suffixes, responses):\n",
    "                response = str(response)\n",
    "                if test_suffix.strip() in response.strip():\n",
    "                    num_exact_matches += 1\n",
    "\n",
    "            # the statistical test using the levenshtein distance\n",
    "            test_prefix_rows = [prefix.split(\"\\n\") for prefix in test_prefixes]\n",
    "            test_result = analysis.levenshtein_distance_t_test(\n",
    "                responses, test_suffixes, test_prefix_rows\n",
    "            )\n",
    "            print(\n",
    "                experiment_utils.bcolors.BOLD\n",
    "                + f'{dataset}, {model}: '\n",
    "                + experiment_utils.bcolors.ENDC\n",
    "                + experiment_utils.bcolors.Black\n",
    "                + f\"{num_exact_matches}/{len(responses)} exact matches. Levenshtein distance test p-value: {test_result.pvalue:.3f}.\"\n",
    "                + experiment_utils.bcolors.ENDC\n",
    "            )\n",
    "        except:\n",
    "            print(f'{dataset}, {model}: error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first token test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in ['IRIS', 'uci-wine', 'titanic-train', 'sklearn-diabetes', 'openml-diabetes', 'california-housing', 'adult', 'spaceship-titanic-train']:\n",
    "    print(dataset)\n",
    "    csv_file = f'../csv/{dataset}.csv'\n",
    "    num_digits = analysis.build_first_token(csv_file)\n",
    "    # statistical prediction of the first token\n",
    "    df_data = utils.load_csv_df(csv_file)\n",
    "    csv_rows = utils.load_csv_rows(csv_file, header=False)\n",
    "    first_tokens = [row[:num_digits] for row in csv_rows]\n",
    "    df_data['FIRST_TOKEN'] = first_tokens\n",
    "    filename = utils.tmp_csv_file(df_data, 'tmp.csv')\n",
    "    statistical_feature_prediction_test(filename, 'FIRST_TOKEN')\n",
    "\n",
    "    \n",
    "\n",
    "    # analysis of model completions\n",
    "    for model in ['gpt-3.5-turbo', 'gpt-4-32k-0314']:\n",
    "        completion_df = pd.read_csv(f'../results/{model}/row-completion/{dataset}.csv', dtype=str)\n",
    "\n",
    "        test_prefixes = completion_df['prefix'].tolist()\n",
    "        test_suffixes = completion_df['suffix'].tolist()\n",
    "        responses = completion_df['response'].tolist()\n",
    "\n",
    "        try:\n",
    "            num_exact_matches = 0\n",
    "            for test_suffix, response in zip(test_suffixes, responses):\n",
    "                response = str(response)\n",
    "                if test_suffix.strip()[:num_digits] == response.strip()[:num_digits]:\n",
    "                    num_exact_matches += 1\n",
    "\n",
    "            print(\n",
    "                experiment_utils.bcolors.BOLD\n",
    "                + f'{dataset}, {model}: '\n",
    "                + experiment_utils.bcolors.ENDC\n",
    "                + experiment_utils.bcolors.Black\n",
    "                + f\"{num_exact_matches}/{len(responses)} ({num_exact_matches / len(responses)}).\"\n",
    "                + experiment_utils.bcolors.ENDC\n",
    "            )\n",
    "        except:\n",
    "            print(f'{dataset}, {model}: error')\n",
    "        \n",
    "    print('-'*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabular-memorization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
